\documentclass{article}
\usepackage[sexy, hdr, fancy]{evan}
\setlength{\droptitle}{-4em}

\lhead{Homework 3}
\rhead{Introduction to Stochastic Processes}
\lfoot{}
\cfoot{\thepage}

\newcommand{\var}{\mathrm{Var}}
\newcommand{\cov}{\mathrm{Cov}}

\begin{document}
\title{Homework 3}
\maketitle
\thispagestyle{fancy}

\section*{Chapter 4: Markov Chains}

\begin{itemize}
	\item[2.] Suppose that whether or not it rains today depends on previous weather conditions through the last three days. Show how this system may be analyzed by using a Markov chain. How many states are needed?
		\begin{soln}
			There are 8 possible states, one for each possible three-day series of weather. If 0 represents sun and 1 represents rain, then the states are 000, 001, 010, 011, 100, 101, 110, 111. 
		\end{soln}

	\item[3.] In Exercise 2, suppose that if it has rained for the past 3 days, then it will rain today with probability 0.8; if it did not rain for any of the past three days, then it will rain today with probability 0.2; and in any other case the weather today will, with probability 0.6, be the same as the weather yesterday. Determine $P$ for this Markov chain.
		\begin{soln}
			If the state is 111, it will have rained for 3 consecutive days, so the probability it stays in 111 is 0.8, and the probability it transitions to 110 is 0.2. Similarly, if it is 000, it transitions to 000 with probability 0.8, and 001 with probability 0.2. For everything else the transition probabilities are 0.6 and 0.4. Thus, we have
			\[P=\begin{bmatrix}
					0.8 & 0.2 & 0 & 0 & 0 & 0 & 0 & 0 \\
					0 & 0 & 0.4 & 0.6 & 0 & 0 & 0 & 0 \\
					0 & 0 & 0 & 0 & 0.6 & 0.4 & 0 & 0 \\
					0 & 0 & 0 & 0 & 0 & 0 & 0.4 & 0.6 \\
					0.6 & 0.4 & 0 & 0 & 0 & 0 & 0 & 0 \\
					0 & 0 & 0.4 & 0.6 & 0 & 0 & 0 & 0 \\
					0 & 0 & 0 & 0 & 0.6 & 0.4 & 0 & 0 \\
					0 & 0 & 0 & 0 & 0 & 0 & 0.2 & 0.8
			\end{bmatrix}\]
		\end{soln}

	\item[5.] A Markov chain $\left\{ X_n, n\ge 0 \right\}$ with states 0, 1, 2, has the transition probability matrix $\begin{bmatrix}
			1/2 & 1/3 & 1/6 \\ 0 & 1/3 & 2/3 \\ 1/2 & 0 & 1/2
		\end{bmatrix}.$ If $P[X_0=0]=P[X_0=1]=1/4,$ find $E[X_3].$
		\begin{soln}
			We take $P^3$ to get the transition matrix for $X_3.$
			\[P^3 = \begin{bmatrix}
					1/2 & 1/3 & 1/6 \\ 0 & 1/3 & 2/3 \\ 1/2 & 0 & 1/2
				\end{bmatrix}^3 = \begin{bmatrix}
					13/36 & 11/54 & 47/108 \\
					4/9 & 4/27 & 11/27 \\
					5/12 & 2/9 & 13/36
			\end{bmatrix}\]
			Now, we have
			\[E[X_3]=0\cdot P[X_3=0] + 1\cdot P[X_3=1] + 2\cdot P[X_3=2]\]
			where
			\begin{align*}
				P[X_3=1] &= \sum_{i=0}^{2}P[X_3=1\mid X_0=i]P[X_0=i] \\
				&= \frac{11}{54}\cdot \frac{1}{4} + \frac{4}{27}\cdot\frac{1}{4} + \frac{2}{9}\cdot\frac{1}{2} = \frac{43}{216} \\
				P[X_3=2] &= \sum_{i=0}^{2}P[X_3=2\mid X_0=i]P[X_0=i] \\
				&= \frac{47}{108}\cdot\frac{1}{4} + \frac{11}{27}\cdot\frac{1}{4} + \frac{13}{36}\cdot\frac{1}{2} = \frac{169}{432}
			\end{align*}
			Thus, the expectation is
			\[E[X_3] = \frac{43}{216} + 2\cdot\frac{169}{432} = \frac{53}{54}\]
		\end{soln}

	\item[6.] Let the transition probability matrix of a two-state Markov chain be given by
		\[P=\begin{bmatrix}
				p & 1-p \\ 1-p & p
		\end{bmatrix}\]
		Show by mathematical induction that
		\[P^{n}=\begin{bmatrix}
				\frac{1}{2} + \frac{1}{2}(2p-1)^n & \frac{1}{2}-\frac{1}{2}(2p-1)^n \\
				\frac{1}{2} - \frac{1}{2}(2p-1)^n & \frac{1}{2}+\frac{1}{2}(2p-1)^n \\
		\end{bmatrix}\]
		\begin{proof}
			The base case is $n=1,$ in which case
			\[P^1=\begin{bmatrix}
					\frac{1}{2}+\frac{1}{2}(2p-1) & \frac{1}{2} - \frac{1}{2}(2p-1) \\
					\frac{1}{2}-\frac{1}{2}(2p-1) & \frac{1}{2} + \frac{1}{2}(2p-1) 
				\end{bmatrix} = \begin{bmatrix}
					p & 1-p \\
					1-p & p
			\end{bmatrix}\]
			Now, suppose the formula holds for arbitrary $k,$ so 
			\[P^k=\begin{bmatrix}
					\frac{1}{2} + \frac{1}{2}(2p-1)^k & \frac{1}{2}-\frac{1}{2}(2p-1)^k \\
					\frac{1}{2} - \frac{1}{2}(2p-1)^k & \frac{1}{2}+\frac{1}{2}(2p-1)^k
			\end{bmatrix}\]
			Then we have
			\begin{align*}
				P^{k+1} &= P^k \cdot P = \begin{bmatrix}
					\frac{1}{2} + \frac{1}{2}(2p-1)^k & \frac{1}{2}-\frac{1}{2}(2p-1)^k \\
					\frac{1}{2} - \frac{1}{2}(2p-1)^k & \frac{1}{2}+\frac{1}{2}(2p-1)^k
				\end{bmatrix}\begin{bmatrix}
					p & 1-p \\ 1-p & p
				\end{bmatrix} = \begin{bmatrix}
					P_{00} & P_{01} \\
					P_{10} & P_{11}
				\end{bmatrix}
			\end{align*}
			where
			\begin{align*}
				P_{00} = P_{11} &= p\left( \frac{1}{2}+\frac{1}{2}(2p-1)^k \right) + (1-p)\left( \frac{1}{2}-\frac{1}{2}(2p-1)^k \right) \\
				&= \frac{p}{2} + \frac{p}{2}(2p-1)^k + \frac{1}{2} - \frac{1}{2}(2p-1)^k - \frac{p}{2} + \frac{p}{2}(2p-1)^k \\
				&= \frac{1}{2} + \left( p-\frac{1}{2} \right)(2p-1)^k = \frac{1}{2} + \frac{1}{2}(2p-1)^{k+1} \\
				P_{01}=P_{10} &= (1-p)\left( \frac{1}{2}+\frac{1}{2}(2p-1)^k \right) + p\left( \frac{1}{2}-\frac{1}{2}(2p-1)^k \right) \\
				&= \frac{1}{2}+\frac{1}{2}(2p-1)^k - \frac{p}{2} + \frac{p}{2}(2p-1)^k + \frac{p}{2} - \frac{p}{2}(2p-1)^k \\
				&= \frac{1}{2} - \left( p-\frac{1}{2} \right)(2p-1)^k = \frac{1}{2}-\frac{1}{2}(2p-1)^k
			\end{align*}
			so the formula holds for $k+1,$ and the statement is proven.
		\end{proof}

	\item[13.] Let $P$ be the transition probability matrix of a Markov chain. Argue that if for some positive integer $r, P^r$ has all positive entries, then so does $P^n,$ for all integers $n\ge r.$

	\item[14.] Specify the classes of the following Markov chains, and determine whether they are transient or recurrent:
		\begin{enumerate}[(a)]
			\item $P_1=\begin{bmatrix}
					0 & 1/2 & 1/2 \\ 1/2 & 0 & 1/2 \\ 1/2 & 1/2 & 0
				\end{bmatrix}$

			\item $P_2=\begin{bmatrix}
					0 & 0 & 0 & 1 \\ 0 & 0 & 0 & 1 \\ 1/2 & 1/2 & 0 & 0 \\ 0 & 0 & 1 & 0
				\end{bmatrix}$

			\item $P_3=\begin{bmatrix}
					1/2 & 0 & 1/2 & 0 & 0 \\
					1/4 & 1/2 & 1/4 & 0 & 0 \\
					1/2 & 0 & 1/2 & 0 & 0 \\
					0 & 0 & 0 & 1/2 & 1/2 \\
					0 & 0 & 0 & 1/2 & 1/2 \\
				\end{bmatrix}$

			\item $P_4=\begin{bmatrix}
					1/4 & 3/4 & 0 & 0 & 0 \\
					1/2 & 1/2 & 0 & 0 & 0 \\
					0 & 0 & 1 & 0 & 0 \\
					0 & 0 & 1/3 & 2/3 & 0 \\
					1 & 0 & 0 & 0 & 0
				\end{bmatrix}$
				
		\end{enumerate}
		
	\item[15.] Prove that if the number of states in a Markov chain is $M,$ and if state $j$ can be reached from state $i,$ then it can be reached in $M$ steps or less.
		
\end{itemize}

\end{document}
