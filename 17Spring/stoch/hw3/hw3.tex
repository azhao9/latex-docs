\documentclass{article}
\usepackage[sexy, hdr, fancy]{evan}
\setlength{\droptitle}{-4em}

\lhead{Homework 3}
\rhead{Introduction to Stochastic Processes}
\lfoot{}
\cfoot{\thepage}

\newcommand{\var}{\mathrm{Var}}
\newcommand{\cov}{\mathrm{Cov}}

\begin{document}
\title{Homework 3}
\maketitle
\thispagestyle{fancy}

\section*{Chapter 4: Markov Chains}

\begin{itemize}
	\item[2.] Suppose that whether or not it rains today depends on previous weather conditions through the last three days. Show how this system may be analyzed by using a Markov chain. How many states are needed?
		\begin{soln}
			There are 8 possible states, one for each possible three-day series of weather. If 0 represents sun and 1 represents rain, then the states are 000, 001, 010, 011, 100, 101, 110, 111. 
		\end{soln}

	\item[3.] In Exercise 2, suppose that if it has rained for the past 3 days, then it will rain today with probability 0.8; if it did not rain for any of the past three days, then it will rain today with probability 0.2; and in any other case the weather today will, with probability 0.6, be the same as the weather yesterday. Determine $P$ for this Markov chain.
		\begin{soln}
			If the state is 111, it will have rained for 3 consecutive days, so the probability it stays in 111 is 0.8, and the probability it transitions to 110 is 0.2. Similarly, if it is 000, it transitions to 000 with probability 0.8, and 001 with probability 0.2. For everything else the transition probabilities are 0.6 and 0.4. Thus, we have
			\[P=\begin{bmatrix}
					0.8 & 0.2 & 0 & 0 & 0 & 0 & 0 & 0 \\
					0 & 0 & 0.4 & 0.6 & 0 & 0 & 0 & 0 \\
					0 & 0 & 0 & 0 & 0.6 & 0.4 & 0 & 0 \\
					0 & 0 & 0 & 0 & 0 & 0 & 0.4 & 0.6 \\
					0.6 & 0.4 & 0 & 0 & 0 & 0 & 0 & 0 \\
					0 & 0 & 0.4 & 0.6 & 0 & 0 & 0 & 0 \\
					0 & 0 & 0 & 0 & 0.6 & 0.4 & 0 & 0 \\
					0 & 0 & 0 & 0 & 0 & 0 & 0.2 & 0.8
			\end{bmatrix}\]
		\end{soln}

	\item[5.] A Markov chain $\left\{ X_n, n\ge 0 \right\}$ with states 0, 1, 2, has the transition probability matrix $\begin{bmatrix}
			1/2 & 1/3 & 1/6 \\ 0 & 1/3 & 2/3 \\ 1/2 & 0 & 1/2
		\end{bmatrix}.$ If $P[X_0=0]=P[X_0=1]=1/4,$ find $E[X_3].$
		\begin{soln}
			We take $P^3$ to get the transition matrix for $X_3.$
			\[P^3 = \begin{bmatrix}
					1/2 & 1/3 & 1/6 \\ 0 & 1/3 & 2/3 \\ 1/2 & 0 & 1/2
				\end{bmatrix}^3 = \begin{bmatrix}
					13/36 & 11/54 & 47/108 \\
					4/9 & 4/27 & 11/27 \\
					5/12 & 2/9 & 13/36
			\end{bmatrix}\]
			Now, we have
			\[E[X_3]=0\cdot P[X_3=0] + 1\cdot P[X_3=1] + 2\cdot P[X_3=2]\]
			where
			\begin{align*}
				P[X_3=1] &= \sum_{i=0}^{2}P[X_3=1\mid X_0=i]P[X_0=i] \\
				&= \frac{11}{54}\cdot \frac{1}{4} + \frac{4}{27}\cdot\frac{1}{4} + \frac{2}{9}\cdot\frac{1}{2} = \frac{43}{216} \\
				P[X_3=2] &= \sum_{i=0}^{2}P[X_3=2\mid X_0=i]P[X_0=i] \\
				&= \frac{47}{108}\cdot\frac{1}{4} + \frac{11}{27}\cdot\frac{1}{4} + \frac{13}{36}\cdot\frac{1}{2} = \frac{169}{432}
			\end{align*}
			Thus, the expectation is
			\[E[X_3] = \frac{43}{216} + 2\cdot\frac{169}{432} = \frac{53}{54}\]
		\end{soln}

	\item[6.] Let the transition probability matrix of a two-state Markov chain be given by
		\[P=\begin{bmatrix}
				p & 1-p \\ 1-p & p
		\end{bmatrix}\]
		Show by mathematical induction that
		\[P^{n}=\begin{bmatrix}
				\frac{1}{2} + \frac{1}{2}(2p-1)^n & \frac{1}{2}-\frac{1}{2}(2p-1)^n \\
				\frac{1}{2} - \frac{1}{2}(2p-1)^n & \frac{1}{2}+\frac{1}{2}(2p-1)^n \\
		\end{bmatrix}\]
		\begin{proof}
			The base case is $n=1,$ in which case
			\[P^1=\begin{bmatrix}
					\frac{1}{2}+\frac{1}{2}(2p-1) & \frac{1}{2} - \frac{1}{2}(2p-1) \\
					\frac{1}{2}-\frac{1}{2}(2p-1) & \frac{1}{2} + \frac{1}{2}(2p-1) 
				\end{bmatrix} = \begin{bmatrix}
					p & 1-p \\
					1-p & p
			\end{bmatrix}\]
			Now, suppose the formula holds for arbitrary $k,$ so 
			\[P^k=\begin{bmatrix}
					\frac{1}{2} + \frac{1}{2}(2p-1)^k & \frac{1}{2}-\frac{1}{2}(2p-1)^k \\
					\frac{1}{2} - \frac{1}{2}(2p-1)^k & \frac{1}{2}+\frac{1}{2}(2p-1)^k
			\end{bmatrix}\]
			Then we have
			\begin{align*}
				P^{k+1} &= P^k \cdot P = \begin{bmatrix}
					\frac{1}{2} + \frac{1}{2}(2p-1)^k & \frac{1}{2}-\frac{1}{2}(2p-1)^k \\
					\frac{1}{2} - \frac{1}{2}(2p-1)^k & \frac{1}{2}+\frac{1}{2}(2p-1)^k
				\end{bmatrix}\begin{bmatrix}
					p & 1-p \\ 1-p & p
				\end{bmatrix} = \begin{bmatrix}
					P_{00} & P_{01} \\
					P_{10} & P_{11}
				\end{bmatrix}
			\end{align*}
			where
			\begin{align*}
				P_{00} = P_{11} &= p\left( \frac{1}{2}+\frac{1}{2}(2p-1)^k \right) + (1-p)\left( \frac{1}{2}-\frac{1}{2}(2p-1)^k \right) \\
				&= \frac{p}{2} + \frac{p}{2}(2p-1)^k + \frac{1}{2} - \frac{1}{2}(2p-1)^k - \frac{p}{2} + \frac{p}{2}(2p-1)^k \\
				&= \frac{1}{2} + \left( p-\frac{1}{2} \right)(2p-1)^k = \frac{1}{2} + \frac{1}{2}(2p-1)^{k+1} \\
				P_{01}=P_{10} &= (1-p)\left( \frac{1}{2}+\frac{1}{2}(2p-1)^k \right) + p\left( \frac{1}{2}-\frac{1}{2}(2p-1)^k \right) \\
				&= \frac{1}{2}+\frac{1}{2}(2p-1)^k - \frac{p}{2} + \frac{p}{2}(2p-1)^k + \frac{p}{2} - \frac{p}{2}(2p-1)^k \\
				&= \frac{1}{2} - \left( p-\frac{1}{2} \right)(2p-1)^k = \frac{1}{2}-\frac{1}{2}(2p-1)^{k+1}
			\end{align*}
			so the formula holds for $k+1,$ and the statement is proven.
		\end{proof}

	\item[13.] Let $P$ be the transition probability matrix of a Markov chain. Argue that if for some positive integer $r, P^r$ has all positive entries, then so does $P^n,$ for all integers $n\ge r.$
		\begin{proof}
			Let $P_{ij}^k$ denote the $(i, j)$ entry in $P^k$ for $k\in\ZZ.$ Then we have the relation
			\[P^{k+1}_{ij} = \sum_{n=0}^{\infty}P^{k}_{in}P_{nj}\]
			If $P$ has a column of all 0s, then it is impossible for $P^r$ to have all positive entries for any integer $r.$ Suppose column $j$ in $P$ was all 0, then $P_{ij}^k=0$ for any $k.$ Thus, $P$ does not have a column of all 0s.

			Now we proceed by induction. The base case is $n=r,$ which is true by assumption. Now suppose for arbitrary $n=m\ge r,$ it holds that $P^m$ has all positive entries. Then we have
			\[P^{m+1}_{ij} = \sum_{n=0}^{\infty}P^m_{in}P_{nj}\]
			Since $P^m_{in}>0, \forall i, n$ and not all of $P_{nj}$ is 0 for any $n,$ this summation must be positive. Thus, the entries of $P^{m+1}$ are all positive, so we are done by induction.
		\end{proof}

	\item[14.] Specify the classes of the following Markov chains, and determine whether they are transient or recurrent:
		\begin{enumerate}[(a)]
			\item $P_1=\begin{bmatrix}
					0 & 1/2 & 1/2 \\ 1/2 & 0 & 1/2 \\ 1/2 & 1/2 & 0
				\end{bmatrix}$
				\begin{soln}
					This Markov chain is irreducible so there is only one class, since all states communicate. To illustrate, we may go from $0\to1\to2\to0.$ Since this is a finite chain and all states communicate, all states must be recurrent.
				\end{soln}

			\item $P_2=\begin{bmatrix}
					0 & 0 & 0 & 1 \\ 0 & 0 & 0 & 1 \\ 1/2 & 1/2 & 0 & 0 \\ 0 & 0 & 1 & 0
				\end{bmatrix}$
				\begin{soln}
					This Markov chain is irreducible so there is only one class, since all states communicate. To illustrate, we may go from $0\to3\to2\to1\to3\to0.$ Since this is a finite chain and all states communicate, all states must be recurrent.
				\end{soln}

			\item $P_3=\begin{bmatrix}
					1/2 & 0 & 1/2 & 0 & 0 \\
					1/4 & 1/2 & 1/4 & 0 & 0 \\
					1/2 & 0 & 1/2 & 0 & 0 \\
					0 & 0 & 0 & 1/2 & 1/2 \\
					0 & 0 & 0 & 1/2 & 1/2 \\
				\end{bmatrix}$
				\begin{soln}
					The classes in this Markov chain are $\left\{ 0, 2 \right\}$ and $\left\{ 3, 4 \right\}$ and $\left\{ 2 \right\}.$ The first and second are recurrent, and the third is transient. We may go from $0\to2\to0$ and $3\to4\to3,$ but once we leave 1, it is impossible to return. 
				\end{soln}

			\item $P_4=\begin{bmatrix}
					1/4 & 3/4 & 0 & 0 & 0 \\
					1/2 & 1/2 & 0 & 0 & 0 \\
					0 & 0 & 1 & 0 & 0 \\
					0 & 0 & 1/3 & 2/3 & 0 \\
					1 & 0 & 0 & 0 & 0
				\end{bmatrix}$
				\begin{soln}
					The classes in this Markov chain are $\left\{ 0, 1 \right\}$ and $\left\{ 2 \right\}$ and $\left\{ 3 \right\}$ and $\left\{ 4 \right\}.$ The first and second are recurrent, and the other two are transient. We may go from $0\to1\to 0$ and state 2 is absorbing. If we are at 3, it is impossible to stay forever, and once we leave, we can't go back. If we are at 4, then we leave for 1, and never return.
				\end{soln}
				
		\end{enumerate}
		
	\item[15.] Prove that if the number of states in a Markov chain is $M,$ and if state $j$ can be reached from state $i,$ then it can be reached in $M$ steps or less.
		\begin{proof}
			If $j$ can be reached from $i,$ then there exists a path from $i$ to $j.$ Suppose on this path, some state was reached twice. Then the sub-path between these two states is a loop, and we can remove it. Thus, on any path from $i$ to $j,$ it is possible to modify it so that no state appears twice. Since there are only a total of $M$ states, it follows that such a path can be modified to be $M$ steps or less.
		\end{proof}
		
\end{itemize}

\section*{Exploration}

\begin{enumerate}[(a)]
	\item For $n\ge 1$ and $k\ge 1,$ write the event $\left\{ T_1=2n, T_2=2k \right\}$ in terms of the partial sums of the random walk.
		\begin{answer*}
			\[\left\{ S_1\neq 0, S_2\neq 0, \cdots, S_{2n-1}\neq 0, S_{2n}=0, S_{2n+1}\neq 0, \cdots, S_{2k-1}\neq 0, S_{2k}=0 \right\}\]
		\end{answer*}

	\item Rewrite the event in terms of the steps $\left\{ X_i \right\}_{i=1}^\infty$ of the random walk.
		\begin{answer*}
			\begin{align*}
				\{ &X_1\neq 0, \cdots, X_1+\cdots+X_{2n-1}\neq 0, X_1+\cdots+X_{2n}=0, \\
				&X_1+\cdots + X_{2n}+X_{2n+1}\neq 0, \cdots, X_1+\cdots+X_{2k-1}\neq 0, X_1+\cdots + X_{2k}=0 \}
			\end{align*}
		\end{answer*}

	\item Show that the event can be written as the intersection of two independent events.
		\begin{soln}
			Since $X_1+\cdots+X_{2n}=0,$ the second line of the event may be written as
			\[\{X_{2n+1}\neq 0, \cdots, X_{2n+1}+\cdots+X_{2k-1}\neq 0, X_{2n+1}+\cdots+X_{2k}=0\}\]
			The first part of the event is independent from this, because none of the $X_i's$ show up in both events. Thus, the event is the intersection
			\begin{align*}
				\{ &X_1\neq 0, \cdots, X_1+\cdots+X_{2n-1}\neq 0, X_1+\cdots+X_{2n}=0\} \cap \\
				\{&X_{2n+1}\neq 0, \cdots, X_{2n+1}+\cdots+X_{2k-1}\neq 0, X_{2n+1}+\cdots + X_{2k}=0 \}
			\end{align*}
		\end{soln}

	\item Write the probability of the event $\left\{ T_1=2n, T_2=2k \right\}$ in terms of the quantities $\left\{ u_{2n} \right\}_{n=1}^\infty$ and $\left\{ f_{2n} \right\}_{n=1}^\infty$ studied in the proof that a first return to the origin is certain.

	\item Calculate $P[T_2=2k]$ for $k\ge1.$

	\item Conclude that $T_2$ is independent of $T_1$ and that they have the same distribution.

	\item Conclude that the probability that a simple symmetric random walk returns to the origin twice is one.

	\item Could the same reasoning be used to show that the random walk returns to the origin three times with probability one?

	\item Suppose we defined $T_3$ to be the additional time after the first return to the origin until the random walk first hits height $m$ for some $m>1.$ Could the same reasoning be used to show that $T_1$ and $T_3$ are independent?
		
\end{enumerate}

\end{document}
