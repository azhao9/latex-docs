\documentclass{article}
\usepackage[sexy, hdr, fancy]{evan}
\setlength{\droptitle}{-4em}

\lhead{Homework 4}
\rhead{Introduction to Stochastic Processes}
\lfoot{}
\cfoot{\thepage}

\newcommand{\var}{\mathrm{Var}}
\newcommand{\cov}{\mathrm{Cov}}

\begin{document}
\title{Homework 4}
\maketitle
\thispagestyle{fancy}

\begin{enumerate}
	\item Consider a Markov chain with state space $\left\{ 1, 2, 3, 4, 5 \right\}$ having transition matrix
		\[P=\begin{bmatrix}
				0 & 1/3 & 2/3 & 0 & 0 \\
				0 & 0 & 0 & 1/4 & 3/4 \\
				0 & 0 & 0 & 1/4 & 3/4 \\
				1 & 0 & 0 & 0 & 0 \\
				1 & 0 & 0 & 0 & 0
		\end{bmatrix}\]

		\begin{enumerate}[(a)]
			\item Is the chain irreducible?
				\begin{answer*}
					We can take a path $1\to 2\to 4\to1\to3\to5\to1,$ so all states communicate and there is only one class, so the chain is irreducible.
				\end{answer*}

			\item Is the chain periodic? If so, what is the period?
				\begin{answer*}
					If we are at 1, we must go to either 2 or 3. From there, the only possibilities are either 4 or 5. From there, the only possibility is 1. Thus, the chain is periodic with period 3.
				\end{answer*}

			\item Does the chain have an invariant distribution? If so, find it.
				\begin{soln}
					Suppose the chain has an invariant distribution $\lambda.$ then we have
					\begin{align*}
						\begin{bmatrix}
							\lambda_1 & \lambda_2 & \lambda_3 & \lambda_4 & \lambda_5
						\end{bmatrix}\begin{bmatrix}
							0 & 1/3 & 2/3 & 0 & 0 \\
							0 & 0 & 0 & 1/4 & 3/4 \\
							0 & 0 & 0 & 1/4 & 3/4 \\
							1 & 0 & 0 & 0 & 0 \\
							1 & 0 & 0 & 0 & 0
						\end{bmatrix}&=\begin{bmatrix}
							\lambda_1 & \lambda_2 & \lambda_3 & \lambda_4 & \lambda_5
						\end{bmatrix} \\
						\begin{bmatrix}
							\lambda_4+\lambda_5 & \frac{1}{3}\lambda_1 & \frac{2}{3}\lambda_1 & \frac{1}{4}\lambda_2 + \frac{1}{4}\lambda_3 & \frac{3}{4}\lambda_2+\frac{3}{4}\lambda_3
						\end{bmatrix} &= \begin{bmatrix}
							\lambda_1 & \lambda_2 & \lambda_3 & \lambda_4 & \lambda_5
						\end{bmatrix}
					\end{align*}
					Solving, we find
					\[\begin{bmatrix}
							\lambda_1 & \lambda_2 & \lambda_3 & \lambda_4 & \lambda_5
						\end{bmatrix} = \begin{bmatrix}
							\frac{1}{3} & \frac{1}{9} & \frac{2}{9} & \frac{1}{12} & \frac{1}{4}
					\end{bmatrix}\]
					which is the invariant distribution.
				\end{soln}

		\end{enumerate}

	\item Let $\left\{ X_n \right\}$ be a Markov chain with state space $E=\left\{ 1, 2, 3, 4, 5 \right\}$ and transition matrix
		\[P=\begin{bmatrix}
				0.4 & 0.5 & 0.1 & 0 & 0 \\
				0 & 0.3 & 0.2 & 0.5 & 0 \\
				0 & 1 & 0 & 0 & 0 \\
				1 & 0 & 0 & 0 & 0 \\
				0.3 & 0.7 & 0 & 0 & 0
		\end{bmatrix}\]

		\begin{enumerate}[(a)]
			\item Classify the states and identify all closed sets and irreducible sets.
				\begin{soln}
					The communication classes (and therefore the irreducible sets) are $\left\{ 5 \right\}$ and $\left\{ 1, 2, 3, 4 \right\},$ since we may take a path $1\to2\to3\to2\to4\to1.$ State 5 is transient because we can never return once we leave, and all other states are recurrent. The only closed sets are $E$ and $\left\{ 1, 2, 3, 4\right\},$ since if we can never reach 5 from any of 1, 2, 3, 4. 
				\end{soln}

			\item Calculate the potential matrix $R$ and the hitting matrix $F.$
				\begin{soln}
					Since states 1, 2, 3, 4 are recurrent, we have $f_{ij}=1$ for $i, j\in\left\{ 1, 2, 3, 4 \right\}.$ If we start at 5, then we will either go to state 1 or 2, and then we are in an irreducible set, so $f_{5j}=1$ for $j\in\left\{ 1, 2, 3, 4 \right\}.$ Now, $f_{i5}=0,$ since we can never return to state 5. Thus, the hitting matrix is
					\[F=\begin{bmatrix}
							1 & 1 & 1 & 1 & 0 \\
							1 & 1 & 1 & 1 & 0 \\
							1 & 1 & 1 & 1 & 0 \\
							1 & 1 & 1 & 1 & 0 \\
							1 & 1 & 1 & 1 & 0
					\end{bmatrix}\]

					For the potential matrix, since states 1, 2, 3, 4 are recurrent, we have $R_{ij}=\infty$ for $i, j\in\left\{ 1, 2, 3, 4 \right\}.$ We have $R_{55}=1$ since $P_{55}^0=1,$ and zero otherwise since we must leave 5 and never return. Then, we have $R_{5j}=\infty$ for $j\in\left\{ 1, 2, 3, 4 \right\}$ since we enter $\left\{ 1, 2, 3, 4 \right\}$ from 5, and then all states are recurrent, and $R_{i5}=0$ for $i\in\left\{ 1, 2, 3, 4 \right\}$ since we can never reach 5. Thus, the potential matrix is
					\[R=\begin{bmatrix}
							\infty & \infty & \infty & \infty & 0 \\
							\infty & \infty & \infty & \infty & 0 \\
							\infty & \infty & \infty & \infty & 0 \\
							\infty & \infty & \infty & \infty & 0 \\
							\infty & \infty & \infty & \infty & 1
					\end{bmatrix}\]
				\end{soln}

			\item What can you say about the asymptotic behavior of the chain?
				\begin{soln}
					Suppose there is a limiting distribution $\lambda,$ so that
					\[\begin{bmatrix}
							\lambda_1 & \lambda_2 & \lambda_3 & \lambda_4 & \lambda_5
						\end{bmatrix} \begin{bmatrix}
							0.4 & 0.5 & 0.1 & 0 & 0 \\
							0 & 0.3 & 0.2 & 0.5 & 0 \\
							0 & 1 & 0 & 0 & 0 \\
							1 & 0 & 0 & 0 & 0 \\
							0.3 & 0.7 & 0 & 0 & 0
						\end{bmatrix} = \begin{bmatrix}
							\lambda_1 & \lambda_2 & \lambda_3 & \lambda_4 & \lambda_5
					\end{bmatrix}\]
					Solving (too trivial to write out), we have 
					\[\begin{bmatrix}
							\lambda_1 & \lambda_2 & \lambda_3 & \lambda_4 & \lambda_5
						\end{bmatrix} = \begin{bmatrix}
							\frac{50}{157} & \frac{60}{157} & \frac{17}{157} & \frac{30}{157} & 0
					\end{bmatrix}\]
					which is the asymptotic behavior.
				\end{soln}

		\end{enumerate}

	\item Prove, or give an explicit counterexample to refute, the following assertion: If $\left\{ X_n \right\}_{n\ge0}$ is a Markov chain, then $\left\{ X_n^2 \right\}_{n\ge0}$ is also a Markov chain.
		\begin{proof}
			Consider a system with states $\left\{ -2, 0, 1, 2 \right\}$ and transition matrix
			\[P=\begin{bmatrix}
					0 & 1 & 0 & 0 \\
					0 & 1 & 0 & 0 \\
					1 & 0 & 0 & 0 \\
					0 & 0 & 0 & 1
			\end{bmatrix}\]
			where $X_n$ transition between these states. Clearly $\left\{ X_n \right\}_{n\ge0}$ is a Markov chain. 

			To see if $\left\{X_n^2\right\}_{n\ge0}$ is a Markov chain, consider the probabilities
			\[P[X_2^2=0\mid X_0^2=4, X_1^2=4]\]
			and
			\[P[X_2^2=0\mid X_1^2=4]\]
			In the first, we must have started at the state 2, since if $X_0=-2,$ then $X_1$ would necessarily have to be 0, but we know that $X_1^2=4.$ Since state 2 only transitions to state 2, the probability is 0. However, the second probability is clearly not 0, because it is possible for $X_1$ to be $-2$ (if $X_0=1,$) in which case we would have $X_2^2=0$ with probability 1. Thus, $\left\{ X_n^2 \right\}_{n\ge0}$ is not a Markov chain.
		\end{proof}

	\item A transition probability matrix $P$ is said to be doubly stochastic if $\displaystyle\sum_{i\in E}^{} P_{i, j}= 1$ for all $j\in E.$ That is, the column sums all equal 1. If a doubly stochastic chain has $n$ states and is irreducible and aperiodic, calculate its limiting probabilities.
		\begin{soln}
			Let $\lambda$ be a stationary distribution. Clearly, letting $\lambda$ be a vector of all $1/n$ works, since
			\begin{align*}
				\begin{bmatrix}
					1/n & 1/n & \cdots & 1/n
				\end{bmatrix}\begin{bmatrix}
					P_{11} & P_{12} & \cdots & P_{1n} \\
					P_{21} & P_{22} & \cdots & P_{2n} \\
					\vdots & \vdots & \ddots & \vdots \\
					P_{n1} & P_{n2} & \cdots & P_{nn}
				\end{bmatrix}&=\begin{bmatrix}
					P_{11}/n + P_{21}/n+\cdots+P_{n1}/n \\
					P_{12}/n +P_{22}/n+\cdots+P_{n2}/n \\
					\vdots \\
					P_{1n}/n + P_{2n}/n+\cdots+P_{nn}/n \\
				\end{bmatrix}^T = \begin{bmatrix}
					1/n \\ 1/n \\ \vdots \\ 1/n
				\end{bmatrix}
			\end{align*}
			since the matrix is double stochastic, so all the $P_{ij}$ in each entry sum to 1. Since the chain is irreducible and aperiodic, this stationary distribution is unique, and corresponds with the limiting distribution.
		\end{soln}

	\item Let $Y_n$ denote the sum of $n$ independent rolls of a fair die. Find
		\[\lim_{n\to\infty} P[Y_n\text{ is a multiple of 13}].\]
		\begin{soln}
			There are 13 possible states, one for each residue modulo 13. For example, if we are at state 8, we can transition to 9, 10, 11, 12, 0, or 1 each with probability $1/6.$ The transition matrix is doubly stochastic, so the limiting probabilities are all $1/13.$ Thus, as $n\to\infty,$ it follows that $Y_n$ is in state 0, corresponding to a sum divisible by 13, with probability $1/13.$
		\end{soln}

	\item Every time the Houston Eulers team wins a game, it wins its next game with probability 0.7. Every time it loses a game, it wins its next game with probability 0.4. If the team wins a game, then it has dinner together with probability 0.8, whereas if the team loses then it has dinner together with probability 0.2. In the long run, what proportion of games result in a team dinner?
		\begin{soln}
			The two states are W and L, and the transition matrix is given by
			\[P=\begin{bmatrix}
					0.7 & 0.3 \\ 0.4 & 0.6
			\end{bmatrix}\]
			We seek a limiting distribution $\lambda,$ where
			\begin{align*}
				\begin{bmatrix}
					\lambda_1 & \lambda_2
				\end{bmatrix}\begin{bmatrix}
					0.7 & 0.3 \\ 0.4 & 0.6
				\end{bmatrix} &= \begin{bmatrix}
					\lambda_1 & \lambda_2
				\end{bmatrix} \\
				\begin{bmatrix}
					0.7\lambda_1+0.4\lambda_2 & 0.3\lambda_1+0.6\lambda_2
				\end{bmatrix}&=\begin{bmatrix}
					\lambda_1 & \lambda_2
				\end{bmatrix}
			\end{align*}
			Solving, we have
			\[\begin{bmatrix}
					\lambda_1 & \lambda_2
				\end{bmatrix} = \begin{bmatrix}
					\frac{4}{7} & \frac{3}{7}
			\end{bmatrix}\]
			Now, if $D$ represents the event that the team gets dinner after any given game, we have
			\begin{align*}
				P[D] &= P[D\mid W]P[W] + P[D\mid L]P[L] \\
				&\to 0.8\left( \frac{4}{7} \right) + 0.2\left( \frac{3}{7} \right) = \frac{19}{35}
			\end{align*}
			so in the long run, about $19/35$ of games result in a team dinner.
		\end{soln}

	\item A professor continually gives exams to her students. She can give three possible types of exams, and her class is graded as having done well or badly. Let $p_i$ denote the probability that the class does well on a type $i$ exam, and suppose that $p_1=0.3, p_2=0.6, p_3=0.9.$ If the class does well on an exam, then the next exam is equally likely to be any of the three types. If the class does badly, then the next exam is always type 1. What proportion of exams are type $i,$ for $i=1, 2, 3?$
		\begin{soln}
			If we are on exam 1, then the next will be exam 2 with probability $0.3\left( \frac{1}{3} \right)=0.1,$ and exam 3 with probability 0.1, and exam 1 with probability 0.8. If we are on exam 2, then the next will be exam 2 with probability $0.6\left( \frac{1}{3} \right)=0.2,$ and exam 3 with probability 0.2, and exam 1 with probability 0.6. If we are on exam 3, then the next will be exam 2 with probability $0.9\left( \frac{1}{3} \right)=0.3,$ and exam 3 with probability 0.3, and exam 1 with probability 0.4. Thus, the transition matrix is given by
			\[P=\begin{bmatrix}
					0.8 & 0.1 & 0.1 \\
					0.6 & 0.2 & 0.2 \\
					0.4 & 0.3 & 0.3
			\end{bmatrix}\]
			We seek a limiting distribution $\lambda,$ where
			\begin{align*}
				\begin{bmatrix}
					\lambda_1 & \lambda_2 & \lambda_3
				\end{bmatrix}\begin{bmatrix}
					0.8 & 0.1 & 0.1 \\
					0.6 & 0.2 & 0.2 \\
					0.4 & 0.3 & 0.3
				\end{bmatrix} &= \begin{bmatrix}
					\lambda_1 & \lambda_2 & \lambda_3
				\end{bmatrix} \\
				\begin{bmatrix}
					0.8\lambda_1 + 0.6\lambda_2+0.4\lambda_3 \\
					0.1\lambda_1+0.2\lambda_2+0.3\lambda_3 \\
					0.1\lambda_1+0.2\lambda_2+0.3\lambda_3
				\end{bmatrix}^T &= \begin{bmatrix}
					\lambda_1 & \lambda_2 & \lambda_3
				\end{bmatrix}
			\end{align*}
			Solving, we have
			\[\begin{bmatrix}
					\lambda_1 & \lambda_2 &\lambda_3
				\end{bmatrix} = \begin{bmatrix}
					\frac{5}{7} & \frac{1}{7} & \frac{1}{7}
			\end{bmatrix}\]
			so approximately $5/7$ of exams will be type 1, and $1/7$ will be type 2, and $1/7$ will be type 3.
		\end{soln}

\end{enumerate}

\end{document}
